# Distributed Training (分散式訓練)

分散式訓練是指將訓練模型的工作負載分散到多台機器的多個 GPU 上進行。

- [Distributed Training (分散式訓練) - 介紹](https://github.com/kaka-lin/ML-Notes/blob/master/Distributed%20Training/introduction.md)

## Pytorch 實作

詳細請看 [here]()
