{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TFRecord files using tf.data\n",
    "\n",
    "The [tf.data](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/data) module also provides tools for reading and writing data in Tensorflow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import all the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-02T08:34:55.207711Z",
     "start_time": "2019-10-02T08:34:53.937592Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "np.random.seed(5)\n",
    "\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-02T08:34:55.214273Z",
     "start_time": "2019-10-02T08:34:55.209338Z"
    }
   },
   "outputs": [],
   "source": [
    "# The following functions can be used to convert a value to a type compatible\n",
    "# with tf.Example.\n",
    "\n",
    "def _bytes_feature(value):\n",
    "    \"\"\"Returns a bytes_list from a string/byte.\"\"\"\n",
    "    if isinstance(value, type(tf.constant(0))):\n",
    "        value = value.numpy() # BytesList won't unpack a string from an EagerTensor.\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "def _float_feature(value):\n",
    "    \"\"\"Return a float_list form a float/double.\"\"\"\n",
    "    return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n",
    "\n",
    "def _int64_feature(value):\n",
    "    \"\"\"Return a int64_list from a bool/enum/int/uint.\"\"\"\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-02T08:34:55.342832Z",
     "start_time": "2019-10-02T08:34:55.216256Z"
    }
   },
   "outputs": [],
   "source": [
    "def serialize_example(feature0, feature1, feature2, feature3):\n",
    "    \"\"\"\n",
    "    Creates a tf.Example message ready to be written to a file.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create a dictionary mapping the feature name to \n",
    "    # the tf.Example-compatible data type\n",
    "    feature = {\n",
    "        'feature0': _int64_feature(feature0),\n",
    "        'feature1': _int64_feature(feature1),\n",
    "        'feature2': _bytes_feature(feature2),\n",
    "        'feature3': _float_feature(feature3),\n",
    "    }\n",
    "    \n",
    "    # Create a Features message using tf.train.Example.\n",
    "    example_proto = tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "    return example_proto.SerializeToString()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing a TFRecord file\n",
    "\n",
    "The easiest way to get the data into a dataset is to use the `from_tensor_slices` method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the observations data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-02T08:34:55.434412Z",
     "start_time": "2019-10-02T08:34:55.346338Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "3\n",
      "b'horse'\n",
      "-1.5667003260129333\n"
     ]
    }
   ],
   "source": [
    "# The number of observations in the dataset.\n",
    "n_observations = int(1e4)\n",
    "\n",
    "# Boolean feature, encoded as False or True.\n",
    "feature0 = np.random.choice([False, True], n_observations)\n",
    "\n",
    "# Integer feature, random from 0 to 4.\n",
    "feature1 = np.random.randint(0, 5, n_observations)\n",
    "\n",
    "# String feature\n",
    "strings = np.array([b'cat', b'dog', b'chicken', b'horse', b'goat'])\n",
    "feature2 = strings[feature1]\n",
    "\n",
    "# Float feature, from a standard normal distribution\n",
    "feature3 = np.random.randn(n_observations)\n",
    "\n",
    "print(feature0[0])\n",
    "print(feature1[0])\n",
    "print(feature2[0])\n",
    "print(feature3[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a `Dataset` from the observations data in memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-02T08:34:55.652920Z",
     "start_time": "2019-10-02T08:34:55.443410Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TensorSliceDataset shapes: ((), (), (), ()), types: (tf.bool, tf.int64, tf.string, tf.float64)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The dimension of all features need to be the same\n",
    "features_dataset = tf.data.Dataset.from_tensor_slices((feature0, feature1, feature2, feature3))\n",
    "features_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take one exmaple from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-02T08:34:55.807015Z",
     "start_time": "2019-10-02T08:34:55.654371Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(True, shape=(), dtype=bool)\n",
      "tf.Tensor(3, shape=(), dtype=int64)\n",
      "tf.Tensor(b'horse', shape=(), dtype=string)\n",
      "tf.Tensor(-1.5667003260129333, shape=(), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "# Use `take(1)` to only pull one example from the dataset.\n",
    "for f0, f1, f2, f3 in features_dataset.take(1):\n",
    "    print(f0)\n",
    "    print(f1)\n",
    "    print(f2)\n",
    "    print(f3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a tf.Example message from the `Dataset`\n",
    "\n",
    "Use the [tf.data.Dataset.map](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/data/Dataset#map) method to apply a function to each element of a Dataset.\n",
    "\n",
    "The mapped function must operate in TensorFlow graph modeâ€”it must operate on and return `tf.Tensors`.\n",
    "\n",
    "- A non-tensor function, like `serialize_example`, can be wrapped with \n",
    "[tf.py_function](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/py_function) to make it compatible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-02T08:34:55.890495Z",
     "start_time": "2019-10-02T08:34:55.808563Z"
    }
   },
   "outputs": [],
   "source": [
    "# Using tf.py_function requires to specify the shape \n",
    "# and type information that is otherwise unavailable\n",
    "def tf_serialize_example(f0, f1, f2, f3):\n",
    "    tf_string = tf.py_function(\n",
    "        serialize_example,\n",
    "        (f0, f1, f2, f3), # pass these args to the above function.\n",
    "        tf.string,        # the return type is `tf.string`.\n",
    "    )     \n",
    "    \n",
    "    return tf.reshape(tf_string, ()) # The result is a scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-02T08:34:55.988805Z",
     "start_time": "2019-10-02T08:34:55.902112Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=25, shape=(), dtype=string, numpy=b'\\nS\\n\\x15\\n\\x08feature2\\x12\\t\\n\\x07\\n\\x05horse\\n\\x14\\n\\x08feature3\\x12\\x08\\x12\\x06\\n\\x04\\xa3\\x89\\xc8\\xbf\\n\\x11\\n\\x08feature0\\x12\\x05\\x1a\\x03\\n\\x01\\x01\\n\\x11\\n\\x08feature1\\x12\\x05\\x1a\\x03\\n\\x01\\x03'>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_serialize_example(f0,f1,f2,f3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply this function (`tf_serialize_example`) to each element in the dataset, and returns a new dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-02T08:34:56.227816Z",
     "start_time": "2019-10-02T08:34:55.994885Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MapDataset shapes: (), types: tf.string>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "serialized_features_dataset = features_dataset.map(tf_serialize_example)\n",
    "serialized_features_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write tf.Example to a TFRecord file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-02T08:34:59.455054Z",
     "start_time": "2019-10-02T08:34:56.229383Z"
    }
   },
   "outputs": [],
   "source": [
    "filename = 'test.tfrecord'\n",
    "writer = tf.data.experimental.TFRecordWriter(filename)\n",
    "writer.write(serialized_features_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading a TFRecord file\n",
    "\n",
    "Then read the TFRecord file using the [tf.data.TFRecordDataset](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/data/TFRecordDataset) class.\n",
    "\n",
    "Using `TFRecordDatasets` can be useful for standardizing input data and optimizing performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-02T08:34:59.468616Z",
     "start_time": "2019-10-02T08:34:59.456411Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TFRecordDatasetV2 shapes: (), types: tf.string>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filenames = [filename]\n",
    "raw_dataset = tf.data.TFRecordDataset(filenames)\n",
    "raw_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we have the dataset that contains serialized [tf.train.Example](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/train/Example) messages. When iterated over it returns these as scalar string tensors.\n",
    "\n",
    "* Note: iterating over a [`tf.data.Dataset`](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/data/Dataset) only works with eager execution enabled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-02T08:34:59.590810Z",
     "start_time": "2019-10-02T08:34:59.470593Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Tensor: id=60058, shape=(), dtype=string, numpy=b'\\nS\\n\\x11\\n\\x08feature0\\x12\\x05\\x1a\\x03\\n\\x01\\x01\\n\\x11\\n\\x08feature1\\x12\\x05\\x1a\\x03\\n\\x01\\x03\\n\\x15\\n\\x08feature2\\x12\\t\\n\\x07\\n\\x05horse\\n\\x14\\n\\x08feature3\\x12\\x08\\x12\\x06\\n\\x04\\xa3\\x89\\xc8\\xbf'>\n",
      "<tf.Tensor: id=60059, shape=(), dtype=string, numpy=b'\\nR\\n\\x11\\n\\x08feature0\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n\\x11\\n\\x08feature1\\x12\\x05\\x1a\\x03\\n\\x01\\x04\\n\\x14\\n\\x08feature2\\x12\\x08\\n\\x06\\n\\x04goat\\n\\x14\\n\\x08feature3\\x12\\x08\\x12\\x06\\n\\x04@\\xb9\\x9b?'>\n",
      "<tf.Tensor: id=60060, shape=(), dtype=string, numpy=b'\\nU\\n\\x14\\n\\x08feature3\\x12\\x08\\x12\\x06\\n\\x04H\\x80\\x87=\\n\\x11\\n\\x08feature0\\x12\\x05\\x1a\\x03\\n\\x01\\x01\\n\\x11\\n\\x08feature1\\x12\\x05\\x1a\\x03\\n\\x01\\x02\\n\\x17\\n\\x08feature2\\x12\\x0b\\n\\t\\n\\x07chicken'>\n",
      "<tf.Tensor: id=60061, shape=(), dtype=string, numpy=b'\\nQ\\n\\x11\\n\\x08feature0\\x12\\x05\\x1a\\x03\\n\\x01\\x01\\n\\x11\\n\\x08feature1\\x12\\x05\\x1a\\x03\\n\\x01\\x01\\n\\x13\\n\\x08feature2\\x12\\x07\\n\\x05\\n\\x03dog\\n\\x14\\n\\x08feature3\\x12\\x08\\x12\\x06\\n\\x04\\x8e\\x13\\xf8?'>\n",
      "<tf.Tensor: id=60062, shape=(), dtype=string, numpy=b'\\nQ\\n\\x11\\n\\x08feature1\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n\\x13\\n\\x08feature2\\x12\\x07\\n\\x05\\n\\x03cat\\n\\x14\\n\\x08feature3\\x12\\x08\\x12\\x06\\n\\x04v\\xa2\\xe1\\xbd\\n\\x11\\n\\x08feature0\\x12\\x05\\x1a\\x03\\n\\x01\\x00'>\n"
     ]
    }
   ],
   "source": [
    "#Use the `.take` method to only show the first 5 records.\n",
    "for raw_record in raw_dataset.take(5):\n",
    "    print(repr(raw_record))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse the `Dataset`\n",
    "\n",
    "These tensors can be parsed using the function below.\n",
    "\n",
    "- Note that the `feature_description` is necessary here because datasets use graph-execution, and need this description to build their shape and type signature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-02T08:34:59.720272Z",
     "start_time": "2019-10-02T08:34:59.592717Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a description of the features.\n",
    "feature_description = {\n",
    "    'feature0': tf.io.FixedLenFeature([], tf.int64, default_value=0),\n",
    "    'feature1': tf.io.FixedLenFeature([], tf.int64, default_value=0),\n",
    "    'feature2': tf.io.FixedLenFeature([], tf.string, default_value=''),\n",
    "    'feature3': tf.io.FixedLenFeature([], tf.float32, default_value=0.0),\n",
    "}\n",
    "\n",
    "def _parse_function(example_proto):\n",
    "  # Parse the input `tf.Example` proto using the dictionary above.\n",
    "  return tf.io.parse_single_example(example_proto, feature_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-02T08:34:59.904226Z",
     "start_time": "2019-10-02T08:34:59.722539Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MapDataset shapes: {feature0: (), feature1: (), feature2: (), feature3: ()}, types: {feature0: tf.int64, feature1: tf.int64, feature2: tf.string, feature3: tf.float32}>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_dataset = raw_dataset.map(_parse_function)\n",
    "parsed_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-02T08:34:59.924248Z",
     "start_time": "2019-10-02T08:34:59.905828Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'feature0': <tf.Tensor: id=60094, shape=(), dtype=int64, numpy=1>, 'feature1': <tf.Tensor: id=60095, shape=(), dtype=int64, numpy=3>, 'feature2': <tf.Tensor: id=60096, shape=(), dtype=string, numpy=b'horse'>, 'feature3': <tf.Tensor: id=60097, shape=(), dtype=float32, numpy=-1.5667003>}\n",
      "{'feature0': <tf.Tensor: id=60098, shape=(), dtype=int64, numpy=0>, 'feature1': <tf.Tensor: id=60099, shape=(), dtype=int64, numpy=4>, 'feature2': <tf.Tensor: id=60100, shape=(), dtype=string, numpy=b'goat'>, 'feature3': <tf.Tensor: id=60101, shape=(), dtype=float32, numpy=1.2165909>}\n",
      "{'feature0': <tf.Tensor: id=60102, shape=(), dtype=int64, numpy=1>, 'feature1': <tf.Tensor: id=60103, shape=(), dtype=int64, numpy=2>, 'feature2': <tf.Tensor: id=60104, shape=(), dtype=string, numpy=b'chicken'>, 'feature3': <tf.Tensor: id=60105, shape=(), dtype=float32, numpy=0.066162646>}\n",
      "{'feature0': <tf.Tensor: id=60106, shape=(), dtype=int64, numpy=1>, 'feature1': <tf.Tensor: id=60107, shape=(), dtype=int64, numpy=1>, 'feature2': <tf.Tensor: id=60108, shape=(), dtype=string, numpy=b'dog'>, 'feature3': <tf.Tensor: id=60109, shape=(), dtype=float32, numpy=1.9380968>}\n",
      "{'feature0': <tf.Tensor: id=60110, shape=(), dtype=int64, numpy=0>, 'feature1': <tf.Tensor: id=60111, shape=(), dtype=int64, numpy=0>, 'feature2': <tf.Tensor: id=60112, shape=(), dtype=string, numpy=b'cat'>, 'feature3': <tf.Tensor: id=60113, shape=(), dtype=float32, numpy=-0.11017315>}\n"
     ]
    }
   ],
   "source": [
    "for parsed_record in parsed_dataset.take(5):\n",
    "    print(repr(parsed_record))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-02T08:34:59.993180Z",
     "start_time": "2019-10-02T08:34:59.926296Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features {\n",
      "  feature {\n",
      "    key: \"feature0\"\n",
      "    value {\n",
      "      int64_list {\n",
      "        value: 1\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"feature1\"\n",
      "    value {\n",
      "      int64_list {\n",
      "        value: 3\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"feature2\"\n",
      "    value {\n",
      "      bytes_list {\n",
      "        value: \"horse\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"feature3\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: -1.5667003393173218\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for raw_record in raw_dataset.take(1):    \n",
    "    example = tf.train.Example()\n",
    "    example.ParseFromString(raw_record.numpy())\n",
    "    print(example)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.2px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
