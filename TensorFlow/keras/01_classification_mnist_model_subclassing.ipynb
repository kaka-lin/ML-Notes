{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-02T09:49:12.456679Z",
     "start_time": "2019-10-02T09:49:01.312378Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n",
      "2.2.4-tf\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "print(tf.__version__)\n",
    "print(tf.keras.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data and preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-02T09:49:13.017410Z",
     "start_time": "2019-10-02T09:49:12.458793Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training images:  (60000, 28, 28, 1)\n",
      "Training lables:  (60000,)\n",
      "Testing images:  (10000, 28, 28, 1)\n",
      "Testing labels:  (10000,)\n",
      "data type:  <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "def load_data():\n",
    "    mnist_dataset = tf.keras.datasets.mnist.load_data()\n",
    "    (x_train, y_train), (x_test, y_test) = mnist_dataset\n",
    "    \n",
    "    ### Preprocess the data\n",
    "    # normalization\n",
    "    # scale pixel value from 0:255 to 0:1\n",
    "    x_train = x_train / 255.0\n",
    "    x_test = x_test / 255.0\n",
    "\n",
    "    # Add a channels dimension\n",
    "    x_train = x_train[..., tf.newaxis]\n",
    "    x_test = x_test[..., tf.newaxis]\n",
    "    \n",
    "    return (x_train, y_train), (x_test, y_test)\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = load_data()\n",
    "\n",
    "print(\"Training images: \", x_train.shape)\n",
    "print(\"Training lables: \", y_train.shape)\n",
    "print(\"Testing images: \", x_test.shape)\n",
    "print(\"Testing labels: \", y_test.shape)\n",
    "print(\"data type: \", type(x_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the data\n",
    "\n",
    "- [matplotlib.pyplot.imshow](https://matplotlib.org/3.1.1/api/_as_gen/matplotlib.pyplot.imshow.html)\n",
    "\n",
    "    - Arguments:\n",
    "    ```\n",
    "    X:  array-like or PIL image. \n",
    "          The image data. Supported array shapes are:\n",
    "\n",
    "          (M, N): an image with scalar data. The data is visualized using a colormap.\n",
    "          (M, N, 3): an image with RGB values (0-1 float or 0-255 int).\n",
    "          (M, N, 4): an image with RGBA values (0-1 float or 0-255 int), i.e. including transparency.\n",
    "        \n",
    "          The first two dimensions (M, N) define the rows and columns of the image.\n",
    "          Out-of-range RGB(A) values are clipped.\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-02T09:49:13.450645Z",
     "start_time": "2019-10-02T09:49:13.019170Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 5\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Label: {}\".format(y_train[0]))\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(x_train[0].squeeze())\n",
    "plt.colorbar()\n",
    "plt.grid(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shuffle the dataset\n",
    "\n",
    "[tf.data.Dataset](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/data/Dataset?hl=zh_tw)\n",
    "\n",
    "- from_tensor_silces: Creates a `Dataset` whose elements are slices of the given tensors. \n",
    "\n",
    "    > Arguments:\n",
    "    ```\n",
    "    shuffle:  uses a fixed-size buffer to shuffle the items as they pass through. \n",
    "    repeat:   restarts the Dataset when it reachs the end.\n",
    "                To limit the number of epochs, set the count argument.\n",
    "    batch:    collects a number of examples and stacks them, to create batches.\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-02T09:49:16.633355Z",
     "start_time": "2019-10-02T09:49:13.452225Z"
    }
   },
   "outputs": [],
   "source": [
    "train_ds = tf.data.Dataset.from_tensor_slices(\n",
    "    (x_train, y_train)).shuffle(10000).batch(32)\n",
    "\n",
    "test_ds = tf.data.Dataset.from_tensor_slices(\n",
    "    (x_test, y_test)).batch(32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model subclassing\n",
    "\n",
    "Create layers in the `__init__` method and set them as attributes of the class instance. Define the forward pass in the `call` method.\n",
    " \n",
    "==> Like `PyTorch`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-02T09:49:16.648823Z",
     "start_time": "2019-10-02T09:49:16.634434Z"
    }
   },
   "outputs": [],
   "source": [
    "class MyModel(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        \n",
    "        # Define your layer here\n",
    "        self.conv1 = Conv2D(32, 3, activation='relu')\n",
    "        self.flatten = Flatten()\n",
    "        self.dense1 = Dense(128, activation='relu')\n",
    "        self.dense2 = Dense(10, activation='softmax')\n",
    "    \n",
    "    def call(self, x):\n",
    "        # Define your forward pass here\n",
    "        x = self.conv1(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.dense1(x)\n",
    "        x = self.dense2(x)\n",
    "        return x\n",
    "\n",
    "model = MyModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile the model\n",
    "\n",
    "Before the model is ready for training, it needs a few more setting.\n",
    "\n",
    "These are added during the model's `compile` step:\n",
    "\n",
    "- Loss function\n",
    "- Optimizer\n",
    "- Metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-02T09:49:26.678425Z",
     "start_time": "2019-10-02T09:49:16.650552Z"
    }
   },
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
    "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
    "test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and testing the mode\n",
    "\n",
    "Use [tf.GradientTape](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/GradientTape?hl=zh_tw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-02T09:49:26.689465Z",
     "start_time": "2019-10-02T09:49:26.680649Z"
    }
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(images, labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(images)\n",
    "        loss = loss_object(labels, predictions)\n",
    "        gradients = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    \n",
    "    train_loss(loss)\n",
    "    train_accuracy(labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-02T09:49:26.772602Z",
     "start_time": "2019-10-02T09:49:26.691930Z"
    }
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def test_step(images, labels):\n",
    "    predictions = model(images)\n",
    "    t_loss = loss_object(labels, predictions)\n",
    "\n",
    "    test_loss(t_loss)\n",
    "    test_accuracy(labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-02T09:50:38.918478Z",
     "start_time": "2019-10-02T09:49:26.779391Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1002 17:49:27.649177 139746901661504 base_layer.py:1814] Layer my_model is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.1393195539712906, Accuracy: 95.80332946777344, Test Loss: 0.06004871428012848, Test Accuracy: 97.97999572753906\n",
      "Epoch 2, Loss: 0.04322228580713272, Accuracy: 98.66166687011719, Test Loss: 0.05162382870912552, Test Accuracy: 98.3699951171875\n",
      "Epoch 3, Loss: 0.023374395444989204, Accuracy: 99.23833465576172, Test Loss: 0.056067634373903275, Test Accuracy: 98.30999755859375\n",
      "Epoch 4, Loss: 0.013499211519956589, Accuracy: 99.5433349609375, Test Loss: 0.05680181086063385, Test Accuracy: 98.4000015258789\n",
      "Epoch 5, Loss: 0.010076966136693954, Accuracy: 99.65499877929688, Test Loss: 0.06585539877414703, Test Accuracy: 98.25\n"
     ]
    }
   ],
   "source": [
    "#tf.keras.backend.set_floatx('float64')\n",
    "\n",
    "EPOCHS = 5\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    for images, labels in train_ds:\n",
    "        train_step(images, labels)\n",
    "    \n",
    "    for test_images, test_labels in test_ds:\n",
    "        test_step(test_images, test_labels)\n",
    "    \n",
    "    template = 'Epoch {}, Loss: {}, Accuracy: {}, Test Loss: {}, Test Accuracy: {}'\n",
    "    print(template.format(epoch+1,\n",
    "                          train_loss.result(),\n",
    "                          train_accuracy.result()*100,\n",
    "                          test_loss.result(),\n",
    "                          test_accuracy.result()*100))\n",
    "    \n",
    "    # Reset the metrics for the next epoch\n",
    "    train_loss.reset_states()\n",
    "    train_accuracy.reset_states()\n",
    "    test_loss.reset_states()\n",
    "    test_accuracy.reset_states()        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "338.188px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
